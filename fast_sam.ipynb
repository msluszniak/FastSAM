{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SegmentationModel(\n",
      "  (model): Sequential(\n",
      "    (0): Conv(\n",
      "      (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "      (act): SiLU(inplace=True)\n",
      "    )\n",
      "    (1): Conv(\n",
      "      (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "      (act): SiLU(inplace=True)\n",
      "    )\n",
      "    (2): C2f(\n",
      "      (cv1): Conv(\n",
      "        (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (cv2): Conv(\n",
      "        (conv): Conv2d(96, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (m): ModuleList(\n",
      "        (0): Bottleneck(\n",
      "          (cv1): Conv(\n",
      "            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (cv2): Conv(\n",
      "            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): Conv(\n",
      "      (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "      (act): SiLU(inplace=True)\n",
      "    )\n",
      "    (4): C2f(\n",
      "      (cv1): Conv(\n",
      "        (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (cv2): Conv(\n",
      "        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (m): ModuleList(\n",
      "        (0-1): 2 x Bottleneck(\n",
      "          (cv1): Conv(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (cv2): Conv(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (5): Conv(\n",
      "      (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "      (act): SiLU(inplace=True)\n",
      "    )\n",
      "    (6): C2f(\n",
      "      (cv1): Conv(\n",
      "        (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (cv2): Conv(\n",
      "        (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (m): ModuleList(\n",
      "        (0-1): 2 x Bottleneck(\n",
      "          (cv1): Conv(\n",
      "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (cv2): Conv(\n",
      "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (7): Conv(\n",
      "      (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "      (act): SiLU(inplace=True)\n",
      "    )\n",
      "    (8): C2f(\n",
      "      (cv1): Conv(\n",
      "        (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (cv2): Conv(\n",
      "        (conv): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (m): ModuleList(\n",
      "        (0): Bottleneck(\n",
      "          (cv1): Conv(\n",
      "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (cv2): Conv(\n",
      "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (9): SPPF(\n",
      "      (cv1): Conv(\n",
      "        (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (cv2): Conv(\n",
      "        (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (m): MaxPool2d(kernel_size=5, stride=1, padding=2, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "    (10): Upsample(scale_factor=2.0, mode='nearest')\n",
      "    (11): Concat()\n",
      "    (12): C2f(\n",
      "      (cv1): Conv(\n",
      "        (conv): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (cv2): Conv(\n",
      "        (conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (m): ModuleList(\n",
      "        (0): Bottleneck(\n",
      "          (cv1): Conv(\n",
      "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (cv2): Conv(\n",
      "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (13): Upsample(scale_factor=2.0, mode='nearest')\n",
      "    (14): Concat()\n",
      "    (15): C2f(\n",
      "      (cv1): Conv(\n",
      "        (conv): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (cv2): Conv(\n",
      "        (conv): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (m): ModuleList(\n",
      "        (0): Bottleneck(\n",
      "          (cv1): Conv(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (cv2): Conv(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (16): Conv(\n",
      "      (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "      (act): SiLU(inplace=True)\n",
      "    )\n",
      "    (17): Concat()\n",
      "    (18): C2f(\n",
      "      (cv1): Conv(\n",
      "        (conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (cv2): Conv(\n",
      "        (conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (m): ModuleList(\n",
      "        (0): Bottleneck(\n",
      "          (cv1): Conv(\n",
      "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (cv2): Conv(\n",
      "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (19): Conv(\n",
      "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "      (act): SiLU(inplace=True)\n",
      "    )\n",
      "    (20): Concat()\n",
      "    (21): C2f(\n",
      "      (cv1): Conv(\n",
      "        (conv): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (cv2): Conv(\n",
      "        (conv): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (m): ModuleList(\n",
      "        (0): Bottleneck(\n",
      "          (cv1): Conv(\n",
      "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (cv2): Conv(\n",
      "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (22): Segment(\n",
      "      (cv2): ModuleList(\n",
      "        (0): Sequential(\n",
      "          (0): Conv(\n",
      "            (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (1): Sequential(\n",
      "          (0): Conv(\n",
      "            (conv): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (2): Sequential(\n",
      "          (0): Conv(\n",
      "            (conv): Conv2d(512, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "      )\n",
      "      (cv3): ModuleList(\n",
      "        (0): Sequential(\n",
      "          (0): Conv(\n",
      "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv(\n",
      "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (1): Sequential(\n",
      "          (0): Conv(\n",
      "            (conv): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv(\n",
      "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (2): Sequential(\n",
      "          (0): Conv(\n",
      "            (conv): Conv2d(512, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv(\n",
      "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "      )\n",
      "      (dfl): DFL(\n",
      "        (conv): Conv2d(16, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      )\n",
      "      (proto): Proto(\n",
      "        (cv1): Conv(\n",
      "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (upsample): ConvTranspose2d(128, 128, kernel_size=(2, 2), stride=(2, 2))\n",
      "        (cv2): Conv(\n",
      "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (cv3): Conv(\n",
      "          (conv): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (cv4): ModuleList(\n",
      "        (0): Sequential(\n",
      "          (0): Conv(\n",
      "            (conv): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv(\n",
      "            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (1): Sequential(\n",
      "          (0): Conv(\n",
      "            (conv): Conv2d(256, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv(\n",
      "            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (2): Sequential(\n",
      "          (0): Conv(\n",
      "            (conv): Conv2d(512, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv(\n",
      "            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mateuszsluszniak/Desktop/AI/sam_research/FastSAM/ultralytics/yolo/utils/torch_utils.py:94: UserWarning: 'has_mps' is deprecated, please use 'torch.backends.mps.is_built()'\n",
      "  elif mps and getattr(torch, 'has_mps', False) and torch.backends.mps.is_available() and TORCH_2_0:\n",
      "\n",
      "image 1/1 /Users/mateuszsluszniak/Desktop/AI/sam_research/FastSAM/images/parrot.jpg: 1024x768 69 objects, 215.9ms\n",
      "Speed: 8.8ms preprocess, 215.9ms inference, 152.9ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "/Users/mateuszsluszniak/Desktop/AI/sam_research/FastSAM/ultralytics/yolo/utils/torch_utils.py:94: UserWarning: 'has_mps' is deprecated, please use 'torch.backends.mps.is_built()'\n",
      "  elif mps and getattr(torch, 'has_mps', False) and torch.backends.mps.is_available() and TORCH_2_0:\n",
      "\n",
      "image 1/1 /Users/mateuszsluszniak/Desktop/AI/sam_research/FastSAM/images/parrot.jpg: 1024x768 69 objects, 33.9ms\n",
      "Speed: 2.6ms preprocess, 33.9ms inference, 7.8ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "image 1/1 /Users/mateuszsluszniak/Desktop/AI/sam_research/FastSAM/images/parrot.jpg: 1024x768 69 objects, 28.0ms\n",
      "Speed: 2.5ms preprocess, 28.0ms inference, 6.3ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "image 1/1 /Users/mateuszsluszniak/Desktop/AI/sam_research/FastSAM/images/parrot.jpg: 1024x768 69 objects, 27.4ms\n",
      "Speed: 2.6ms preprocess, 27.4ms inference, 6.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "image 1/1 /Users/mateuszsluszniak/Desktop/AI/sam_research/FastSAM/images/parrot.jpg: 1024x768 69 objects, 27.3ms\n",
      "Speed: 2.8ms preprocess, 27.3ms inference, 6.9ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "image 1/1 /Users/mateuszsluszniak/Desktop/AI/sam_research/FastSAM/images/parrot.jpg: 1024x768 69 objects, 27.5ms\n",
      "Speed: 3.3ms preprocess, 27.5ms inference, 6.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "image 1/1 /Users/mateuszsluszniak/Desktop/AI/sam_research/FastSAM/images/parrot.jpg: 1024x768 69 objects, 27.8ms\n",
      "Speed: 2.6ms preprocess, 27.8ms inference, 6.1ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "image 1/1 /Users/mateuszsluszniak/Desktop/AI/sam_research/FastSAM/images/parrot.jpg: 1024x768 69 objects, 27.6ms\n",
      "Speed: 2.5ms preprocess, 27.6ms inference, 6.3ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "image 1/1 /Users/mateuszsluszniak/Desktop/AI/sam_research/FastSAM/images/parrot.jpg: 1024x768 69 objects, 27.4ms\n",
      "Speed: 2.3ms preprocess, 27.4ms inference, 6.3ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "image 1/1 /Users/mateuszsluszniak/Desktop/AI/sam_research/FastSAM/images/parrot.jpg: 1024x768 69 objects, 27.1ms\n",
      "Speed: 2.7ms preprocess, 27.1ms inference, 6.1ms postprocess per image at shape (1, 3, 1024, 1024)\n"
     ]
    }
   ],
   "source": [
    "from fastsam import FastSAM, FastSAMPrompt\n",
    "import torch\n",
    "import lovely_tensors\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import math\n",
    "import time\n",
    "import cv2\n",
    "import onnxruntime\n",
    "lovely_tensors.monkey_patch()\n",
    "\n",
    "model = FastSAM('./weights/FastSAM-s.pt')\n",
    "IMAGE_PATH = './images/parrot.jpg'\n",
    "DEVICE = 'mps'\n",
    "\n",
    "print(model.model)\n",
    "for _ in range(10):\n",
    "    everything_results = model(IMAGE_PATH, device=DEVICE, retina_masks=True, imgsz=1024, conf=0.4, iou=0.9,)\n",
    "\n",
    "prompt_process = FastSAMPrompt(IMAGE_PATH, everything_results, device=DEVICE)\n",
    "\n",
    "# everything prompt\n",
    "ann = prompt_process.everything_prompt()\n",
    "\n",
    "prompt_process.plot(annotations=ann,output_path='./output/cat.jpg',)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ultralytics.nn.tasks.SegmentationModel"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(model.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m decoder \u001b[38;5;241m=\u001b[39m FastSAMDecoder(model)\n\u001b[1;32m      3\u001b[0m x \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(Image\u001b[38;5;241m.\u001b[39mopen(IMAGE_PATH))\n\u001b[0;32m----> 4\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_encoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/AI/sam_research/FastSAM/fastsam/decoder.py:38\u001b[0m, in \u001b[0;36mFastSAMDecoder.run_encoder\u001b[0;34m(self, image)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimage \u001b[38;5;241m=\u001b[39m image\n\u001b[1;32m     30\u001b[0m image_embedding \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimage, \n\u001b[1;32m     32\u001b[0m     device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice, \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     36\u001b[0m     iou\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miou\n\u001b[1;32m     37\u001b[0m     )\n\u001b[0;32m---> 38\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimage_embedding\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mnumpy()\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "from fastsam import FastSAMDecoder\n",
    "decoder = FastSAMDecoder(model)\n",
    "x = np.array(Image.open(IMAGE_PATH))\n",
    "res = decoder.run_encoder(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'res' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mres\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'res' is not defined"
     ]
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m x \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(Image\u001b[38;5;241m.\u001b[39mopen(IMAGE_PATH))\n\u001b[0;32m----> 2\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_encoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(res)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# print(res.shape)\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/AI/sam_research/FastSAM/fastsam/decoder.py:38\u001b[0m, in \u001b[0;36mFastSAMDecoder.run_encoder\u001b[0;34m(self, image)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimage \u001b[38;5;241m=\u001b[39m image\n\u001b[1;32m     30\u001b[0m image_embedding \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimage, \n\u001b[1;32m     32\u001b[0m     device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice, \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     36\u001b[0m     iou\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miou\n\u001b[1;32m     37\u001b[0m     )\n\u001b[0;32m---> 38\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimage_embedding\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mnumpy()\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "x = np.array(Image.open(IMAGE_PATH))\n",
    "res = decoder.run_encoder(x)\n",
    "print(res)\n",
    "# print(res.shape)\n",
    "\n",
    "print(res.masks.masks.shape)\n",
    "# print(x.shape)\n",
    "# x = torch.Tensor(x)\n",
    "# x = torch.permute(x, (2, 0, 1))\n",
    "# x = x.unsqueeze(0)\n",
    "# print(x.size())\n",
    "# x = x[:, :, :1920, :1024]\n",
    "# print(model.model(x)[0].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "torch.cat(): expected a non-empty list of Tensors",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 22\u001b[0m\n\u001b[1;32m     16\u001b[0m     im \u001b[38;5;241m=\u001b[39m im[\u001b[38;5;28;01mNone\u001b[39;00m]  \u001b[38;5;66;03m# expand for batch dim\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Load the compiled model\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# model = torch.jit.load('model_converted.pt')\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# Inference\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mim\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(pred)\n\u001b[1;32m     24\u001b[0m pred \u001b[38;5;241m=\u001b[39m non_max_suppression(pred) \u001b[38;5;66;03m#nms function used same as yolov5 detect.py\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/FastSAM/lib/python3.9/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/FastSAM/lib/python3.9/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/AI/sam_research/FastSAM/ultralytics/nn/tasks.py:45\u001b[0m, in \u001b[0;36mBaseModel.forward\u001b[0;34m(self, x, *args, **kwargs)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mdict\u001b[39m):  \u001b[38;5;66;03m# for cases of training and validating while training.\u001b[39;00m\n\u001b[1;32m     44\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss(x, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m---> 45\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/AI/sam_research/FastSAM/ultralytics/nn/tasks.py:62\u001b[0m, in \u001b[0;36mBaseModel.predict\u001b[0;34m(self, x, profile, visualize, augment)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m augment:\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_predict_augment(x)\n\u001b[0;32m---> 62\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predict_once\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprofile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvisualize\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/AI/sam_research/FastSAM/ultralytics/nn/tasks.py:82\u001b[0m, in \u001b[0;36mBaseModel._predict_once\u001b[0;34m(self, x, profile, visualize)\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m profile:\n\u001b[1;32m     81\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_profile_one_layer(m, x, dt)\n\u001b[0;32m---> 82\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# run\u001b[39;00m\n\u001b[1;32m     83\u001b[0m y\u001b[38;5;241m.\u001b[39mappend(x \u001b[38;5;28;01mif\u001b[39;00m m\u001b[38;5;241m.\u001b[39mi \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)  \u001b[38;5;66;03m# save output\u001b[39;00m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m visualize:\n",
      "File \u001b[0;32m~/miniconda3/envs/FastSAM/lib/python3.9/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/FastSAM/lib/python3.9/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/AI/sam_research/FastSAM/ultralytics/nn/modules/head.py:94\u001b[0m, in \u001b[0;36mSegment.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     91\u001b[0m bs \u001b[38;5;241m=\u001b[39m p\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]  \u001b[38;5;66;03m# batch size\u001b[39;00m\n\u001b[1;32m     93\u001b[0m mc \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcv4[i](x[i])\u001b[38;5;241m.\u001b[39mview(bs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnm, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnl)], \u001b[38;5;241m2\u001b[39m)  \u001b[38;5;66;03m# mask coefficients\u001b[39;00m\n\u001b[0;32m---> 94\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetect\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining:\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x, mc, p\n",
      "File \u001b[0;32m~/Desktop/AI/sam_research/FastSAM/ultralytics/nn/modules/head.py:51\u001b[0m, in \u001b[0;36mDetect.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdynamic \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m!=\u001b[39m shape:\n\u001b[0;32m---> 51\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39manchors, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstrides \u001b[38;5;241m=\u001b[39m (x\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m \u001b[43mmake_anchors\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m=\u001b[39m shape\n\u001b[1;32m     54\u001b[0m x_cat \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([xi\u001b[38;5;241m.\u001b[39mview(shape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mno, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m xi \u001b[38;5;129;01min\u001b[39;00m x], \u001b[38;5;241m2\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/AI/sam_research/FastSAM/ultralytics/yolo/utils/tal.py:272\u001b[0m, in \u001b[0;36mmake_anchors\u001b[0;34m(feats, strides, grid_cell_offset)\u001b[0m\n\u001b[1;32m    268\u001b[0m     stride_tensor\u001b[38;5;241m.\u001b[39mappend(torch\u001b[38;5;241m.\u001b[39mzeros((h \u001b[38;5;241m*\u001b[39m w, \u001b[38;5;241m1\u001b[39m), dtype\u001b[38;5;241m=\u001b[39mdtype, device\u001b[38;5;241m=\u001b[39mdevice))\n\u001b[1;32m    269\u001b[0m     \u001b[38;5;66;03m# anchor_points[i] += torch.stack((sx, sy), -1).view(-1, 2)\u001b[39;00m\n\u001b[1;32m    270\u001b[0m     \u001b[38;5;66;03m# stride_tensor[i] += stride\u001b[39;00m\n\u001b[1;32m    271\u001b[0m \u001b[38;5;66;03m# print(anchor_points)\u001b[39;00m\n\u001b[0;32m--> 272\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43manchor_points\u001b[49m\u001b[43m)\u001b[49m, torch\u001b[38;5;241m.\u001b[39mcat(stride_tensor)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: torch.cat(): expected a non-empty list of Tensors"
     ]
    }
   ],
   "source": [
    "from ultralytics.yolo.utils.ops import non_max_suppression\n",
    "\n",
    "\n",
    "CLASSES = list(range(1000))\n",
    "im = cv2.imread(IMAGE_PATH)\n",
    "img0 = im.copy()\n",
    "im = cv2.resize(im, (1024, 1024), interpolation = cv2.INTER_AREA)\n",
    "# Convert\n",
    "im = im.transpose((2, 0, 1))[::-1]  # HWC to CHW, BGR to RGB\n",
    "im = np.ascontiguousarray(im)\n",
    "# Convert into torch\n",
    "im = torch.from_numpy(im)\n",
    "im = im.float()  # uint8 to fp16/32\n",
    "im /= 255  # 0 - 255 to 0.0 - 1.0\n",
    "if len(im.shape) == 3:\n",
    "    im = im[None]  # expand for batch dim\n",
    "\n",
    "# Load the compiled model\n",
    "# model = torch.jit.load('model_converted.pt')\n",
    "\n",
    "# Inference\n",
    "pred = model.model(im)\n",
    "print(pred)\n",
    "pred = non_max_suppression(pred) #nms function used same as yolov5 detect.py\n",
    "\n",
    "#Process predictions\n",
    "for i, det in enumerate(pred):  # per image\n",
    "    im0 = img0.copy()\n",
    "    color=(30, 30, 30)\n",
    "    txt_color=(255, 255, 255)\n",
    "    h_size, w_size = im.shape[-2:]\n",
    "    # print(h_size, w_size)\n",
    "    lw = max(round(sum(im.shape) / 2 * 0.003), 2) \n",
    "\n",
    "    if len(det):\n",
    "        # Write results\n",
    "        for *xyxy, conf, cls in reversed(det):\n",
    "            c = int(cls)  # integer class\n",
    "            label = f'{CLASSES[c]} {conf:.2f}'\n",
    "            print(label)\n",
    "            box = xyxy\n",
    "            print(box)\n",
    "            p1, p2 = (int(box[0]), int(box[1])), (int(box[2]), int(box[3]))\n",
    "            cv2.rectangle(im0, p1, p2, color, thickness=lw, lineType=cv2.LINE_AA)\n",
    "            tf = max(lw - 1, 1)  # font thickness\n",
    "            w, h = cv2.getTextSize(label, 0, fontScale=lw / 3, thickness=tf)[0]  # text width, height\n",
    "            outside = p1[1] - h - 3 >= 0  # label fits outside box\n",
    "            p2 = p1[0] + w, p1[1] - h - 3 if outside else p1[1] + h + 3\n",
    "            print(p1, p2)\n",
    "            cv2.rectangle(im0, p1, p2, color, -1, cv2.LINE_AA)  # filled\n",
    "            cv2.putText(im0,\n",
    "                        label, (p1[0], p1[1] - 2 if outside else p1[1] + h + 2),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                        1,\n",
    "                        (255, 0, 0),\n",
    "                        thickness=2,\n",
    "                        lineType=cv2.LINE_AA)\n",
    "    # Save results (image with detections)\n",
    "    # cv2.putText(im0,\n",
    "    #                     label, (50, 50),\n",
    "    #                     cv2.FONT_HERSHEY_SIMPLEX,\n",
    "    #                     1,\n",
    "    #                     (255, 0, 0),\n",
    "    #                     thickness=2,\n",
    "    #                     lineType=cv2.LINE_AA)\n",
    "    status = cv2.imwrite('out.jpg', im0)\n",
    "    print(\"status \", status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 1024, 1024])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "torch.cat(): expected a non-empty list of Tensors",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 32\u001b[0m\n\u001b[1;32m     30\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m     31\u001b[0m sp\u001b[38;5;241m.\u001b[39mbatch \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage_test.jpg\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 32\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mim\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m x\n\u001b[1;32m     34\u001b[0m im\u001b[38;5;241m.\u001b[39mpermute((\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m))\n",
      "File \u001b[0;32m~/miniconda3/envs/FastSAM/lib/python3.9/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/FastSAM/lib/python3.9/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/AI/sam_research/FastSAM/ultralytics/nn/tasks.py:45\u001b[0m, in \u001b[0;36mBaseModel.forward\u001b[0;34m(self, x, *args, **kwargs)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mdict\u001b[39m):  \u001b[38;5;66;03m# for cases of training and validating while training.\u001b[39;00m\n\u001b[1;32m     44\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss(x, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m---> 45\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/AI/sam_research/FastSAM/ultralytics/nn/tasks.py:62\u001b[0m, in \u001b[0;36mBaseModel.predict\u001b[0;34m(self, x, profile, visualize, augment)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m augment:\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_predict_augment(x)\n\u001b[0;32m---> 62\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predict_once\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprofile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvisualize\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/AI/sam_research/FastSAM/ultralytics/nn/tasks.py:82\u001b[0m, in \u001b[0;36mBaseModel._predict_once\u001b[0;34m(self, x, profile, visualize)\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m profile:\n\u001b[1;32m     81\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_profile_one_layer(m, x, dt)\n\u001b[0;32m---> 82\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# run\u001b[39;00m\n\u001b[1;32m     83\u001b[0m y\u001b[38;5;241m.\u001b[39mappend(x \u001b[38;5;28;01mif\u001b[39;00m m\u001b[38;5;241m.\u001b[39mi \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)  \u001b[38;5;66;03m# save output\u001b[39;00m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m visualize:\n",
      "File \u001b[0;32m~/miniconda3/envs/FastSAM/lib/python3.9/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/FastSAM/lib/python3.9/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/AI/sam_research/FastSAM/ultralytics/nn/modules/head.py:94\u001b[0m, in \u001b[0;36mSegment.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     91\u001b[0m bs \u001b[38;5;241m=\u001b[39m p\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]  \u001b[38;5;66;03m# batch size\u001b[39;00m\n\u001b[1;32m     93\u001b[0m mc \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcv4[i](x[i])\u001b[38;5;241m.\u001b[39mview(bs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnm, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnl)], \u001b[38;5;241m2\u001b[39m)  \u001b[38;5;66;03m# mask coefficients\u001b[39;00m\n\u001b[0;32m---> 94\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetect\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining:\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x, mc, p\n",
      "File \u001b[0;32m~/Desktop/AI/sam_research/FastSAM/ultralytics/nn/modules/head.py:51\u001b[0m, in \u001b[0;36mDetect.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdynamic \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m!=\u001b[39m shape:\n\u001b[0;32m---> 51\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39manchors, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstrides \u001b[38;5;241m=\u001b[39m (x\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m \u001b[43mmake_anchors\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m=\u001b[39m shape\n\u001b[1;32m     54\u001b[0m x_cat \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([xi\u001b[38;5;241m.\u001b[39mview(shape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mno, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m xi \u001b[38;5;129;01min\u001b[39;00m x], \u001b[38;5;241m2\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/AI/sam_research/FastSAM/ultralytics/yolo/utils/tal.py:272\u001b[0m, in \u001b[0;36mmake_anchors\u001b[0;34m(feats, strides, grid_cell_offset)\u001b[0m\n\u001b[1;32m    268\u001b[0m     stride_tensor\u001b[38;5;241m.\u001b[39mappend(torch\u001b[38;5;241m.\u001b[39mzeros((h \u001b[38;5;241m*\u001b[39m w, \u001b[38;5;241m1\u001b[39m), dtype\u001b[38;5;241m=\u001b[39mdtype, device\u001b[38;5;241m=\u001b[39mdevice))\n\u001b[1;32m    269\u001b[0m     \u001b[38;5;66;03m# anchor_points[i] += torch.stack((sx, sy), -1).view(-1, 2)\u001b[39;00m\n\u001b[1;32m    270\u001b[0m     \u001b[38;5;66;03m# stride_tensor[i] += stride\u001b[39;00m\n\u001b[1;32m    271\u001b[0m \u001b[38;5;66;03m# print(anchor_points)\u001b[39;00m\n\u001b[0;32m--> 272\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43manchor_points\u001b[49m\u001b[43m)\u001b[49m, torch\u001b[38;5;241m.\u001b[39mcat(stride_tensor)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: torch.cat(): expected a non-empty list of Tensors"
     ]
    }
   ],
   "source": [
    "from ultralytics.yolo.v8.segment.predict import *\n",
    "from ultralytics.yolo.utils import ops\n",
    "import torch\n",
    "from ultralytics.nn.tasks import attempt_load_one_weight\n",
    "import cv2\n",
    "import numpy as np\n",
    "# state_dict = torch.load('./weights/FastSAM-s.pt')\n",
    "# model = FastSAM.load_state_dict(state_dict)\n",
    "\n",
    "model, _ = attempt_load_one_weight('./weights/FastSAM-s.pt')\n",
    "IMAGE_PATH = './images/parrot.jpg'\n",
    "im = cv2.imread(IMAGE_PATH)\n",
    "img0 = im.copy()\n",
    "im = cv2.resize(im, (1024, 1024), interpolation = cv2.INTER_AREA)\n",
    "im = im.transpose((2, 0, 1))[::-1]  # HWC to CHW, BGR to RGB\n",
    "im = np.ascontiguousarray(im)\n",
    "# Convert into torch\n",
    "im = torch.from_numpy(im)\n",
    "im = im.float()  # uint8 to fp16/32\n",
    "im /= 255  # 0 - 255 to 0.0 - 1.0\n",
    "if len(im.shape) == 3:\n",
    "    im = im[None]  # expand for batch dim\n",
    "\n",
    "print(im.size())\n",
    "\n",
    "# sp = SegmentationPredictor(overrides=model.overrides, _callbacks=model.callbacks)\n",
    "sp = SegmentationPredictor()\n",
    "# sp.setup_model(model.model)\n",
    "sp.device = 'mps'\n",
    "model.eval()\n",
    "sp.batch = \"image_test.jpg\"\n",
    "x = model(im)\n",
    "x\n",
    "im.permute((0, 3, 1, 2))\n",
    "def postprocess(sp, preds, img, orig_imgs):\n",
    "    \"\"\"TODO: filter by classes.\"\"\"\n",
    "    p = ops.non_max_suppression(preds[0],\n",
    "                                sp.args.conf,\n",
    "                                sp.args.iou,\n",
    "                                agnostic=sp.args.agnostic_nms,\n",
    "                                max_det=sp.args.max_det,\n",
    "                                nc=len(model.names),\n",
    "                                classes=sp.args.classes)\n",
    "    results = []\n",
    "    proto = preds[1][-1] if len(preds[1]) == 3 else preds[1]  # second output is len 3 if pt, but only 1 if exported\n",
    "    for i, pred in enumerate(p):\n",
    "        orig_img = orig_imgs[i] if isinstance(orig_imgs, list) else orig_imgs\n",
    "        path = sp.batch[0]\n",
    "        img_path = path[i] if isinstance(path, list) else path\n",
    "        if not len(pred):  # save empty boxes\n",
    "            results.append(Results(orig_img=orig_img, path=img_path, names=model.names, boxes=pred[:, :6]))\n",
    "            continue\n",
    "        if sp.args.retina_masks:\n",
    "            if not isinstance(orig_imgs, torch.Tensor):\n",
    "                pred[:, :4] = ops.scale_boxes(img.shape[2:], pred[:, :4], orig_img.shape)\n",
    "            masks = ops.process_mask_native(proto[i], pred[:, 6:], pred[:, :4], orig_img.shape[:2])  # HWC\n",
    "        else:\n",
    "            masks = ops.process_mask(proto[i], pred[:, 6:], pred[:, :4], img.shape[2:], upsample=True)  # HWC\n",
    "            if not isinstance(orig_imgs, torch.Tensor):\n",
    "                pred[:, :4] = ops.scale_boxes(img.shape[2:], pred[:, :4], orig_img.shape)\n",
    "        results.append(\n",
    "            Results(orig_img=orig_img, path=img_path, names=model.names, boxes=pred[:, :6], masks=masks))\n",
    "    return results\n",
    "\n",
    "print(\"sp.args.cond\", sp.args.conf)\n",
    "print(\"sp.args.iou\", sp.args.iou)\n",
    "print(\"sp.args.agnostic_nms\", sp.args.agnostic_nms)\n",
    "print(\"sp.args.max_det\", sp.args.max_det)\n",
    "print(\"model.model.names\", model.names)\n",
    "print(\"sp.args.classes\", sp.args.classes)\n",
    "print(\"sp.batch[0]\", sp.batch[0])\n",
    "print(\"sp.args.retina_masks\", sp.args.retina_masks)\n",
    "\n",
    "res = postprocess(sp, x, im, im)\n",
    "# res = sp.postprocess(x, im, im)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/mateuszsluszniak/Desktop/AI/sam_research/FastSAM'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# print(sp.args.retina_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialized only for plotting \n",
    "prompt_process = FastSAMPrompt(IMAGE_PATH, res, device=DEVICE)\n",
    "\n",
    "# everything prompt\n",
    "ann = res[0].masks.data\n",
    "# ann = prompt_process.everything_prompt()\n",
    "\n",
    "\n",
    "prompt_process.plot(annotations=ann,output_path='./output/parrot.jpg',)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand((1, 3, 1024, 1024))\n",
    "model.model.eval()\n",
    "res1, res2 = model.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor[1, 37, 21504] n=795648 (3.0Mb) x∈[-4.462, 1.022e+03] μ=29.680 σ=136.337"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([tensor[1, 65, 128, 128] n=1064960 (4.1Mb) x∈[-11.530, 13.182] μ=0.858 σ=3.624,\n",
       "  tensor[1, 65, 64, 64] n=266240 (1.0Mb) x∈[-12.244, 11.366] μ=0.854 σ=3.004,\n",
       "  tensor[1, 65, 32, 32] n=66560 (0.3Mb) x∈[-14.146, 8.306] μ=0.854 σ=2.298],\n",
       " tensor[1, 32, 21504] n=688128 (2.6Mb) x∈[-4.462, 2.603] μ=-0.115 σ=0.843,\n",
       " tensor[1, 32, 256, 256] n=2097152 (8Mb) x∈[-0.278, 5.295] μ=0.835 σ=0.729)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'FastSAM' object has no attribute 'point_prompt'. See valid attributes below.\nNone",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpoint_prompt\u001b[49m([[\u001b[38;5;241m200\u001b[39m, \u001b[38;5;241m400\u001b[39m]], [\u001b[38;5;241m1\u001b[39m])\n",
      "File \u001b[0;32m~/Desktop/AI/sam_research/FastSAM/fastsam/model.py:106\u001b[0m, in \u001b[0;36mFastSAM.__getattr__\u001b[0;34m(self, attr)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Raises error if object has no requested attribute.\"\"\"\u001b[39;00m\n\u001b[1;32m    105\u001b[0m name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\n\u001b[0;32m--> 106\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. See valid attributes below.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__doc__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'FastSAM' object has no attribute 'point_prompt'. See valid attributes below.\nNone"
     ]
    }
   ],
   "source": [
    "model.point_prompt([[200, 400]], [1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'object'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import time\n",
    "import cv2\n",
    "import numpy as np\n",
    "import onnxruntime\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "class_names = ['person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat', 'traffic light',\n",
    "               'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow',\n",
    "               'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee',\n",
    "               'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard',\n",
    "               'tennis racket', 'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple',\n",
    "               'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch',\n",
    "               'potted plant', 'bed', 'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote', 'keyboard',\n",
    "               'cell phone', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase',\n",
    "               'scissors', 'teddy bear', 'hair drier', 'toothbrush']\n",
    "\n",
    "# Create a list of colors for each class where each color is a tuple of 3 integer values\n",
    "rng = np.random.default_rng(3)\n",
    "colors = rng.uniform(0, 255, size=(len(class_names), 3))\n",
    "\n",
    "\n",
    "def nms(boxes, scores, iou_threshold):\n",
    "    # Sort by score\n",
    "    sorted_indices = np.argsort(scores)[::-1]\n",
    "\n",
    "    keep_boxes = []\n",
    "    while sorted_indices.size > 0:\n",
    "        # Pick the last box\n",
    "        box_id = sorted_indices[0]\n",
    "        keep_boxes.append(box_id)\n",
    "\n",
    "        # Compute IoU of the picked box with the rest\n",
    "        ious = compute_iou(boxes[box_id, :], boxes[sorted_indices[1:], :])\n",
    "\n",
    "        # Remove boxes with IoU over the threshold\n",
    "        keep_indices = np.where(ious < iou_threshold)[0]\n",
    "\n",
    "        # print(keep_indices.shape, sorted_indices.shape)\n",
    "        sorted_indices = sorted_indices[keep_indices + 1]\n",
    "\n",
    "    return keep_boxes\n",
    "\n",
    "\n",
    "def compute_iou(box, boxes):\n",
    "    # Compute xmin, ymin, xmax, ymax for both boxes\n",
    "    xmin = np.maximum(box[0], boxes[:, 0])\n",
    "    ymin = np.maximum(box[1], boxes[:, 1])\n",
    "    xmax = np.minimum(box[2], boxes[:, 2])\n",
    "    ymax = np.minimum(box[3], boxes[:, 3])\n",
    "\n",
    "    # Compute intersection area\n",
    "    intersection_area = np.maximum(0, xmax - xmin) * np.maximum(0, ymax - ymin)\n",
    "\n",
    "    # Compute union area\n",
    "    box_area = (box[2] - box[0]) * (box[3] - box[1])\n",
    "    boxes_area = (boxes[:, 2] - boxes[:, 0]) * (boxes[:, 3] - boxes[:, 1])\n",
    "    union_area = box_area + boxes_area - intersection_area\n",
    "\n",
    "    # Compute IoU\n",
    "    iou = intersection_area / union_area\n",
    "\n",
    "    return iou\n",
    "\n",
    "\n",
    "def xywh2xyxy(x):\n",
    "    # Convert bounding box (x, y, w, h) to bounding box (x1, y1, x2, y2)\n",
    "    y = np.copy(x)\n",
    "    y[..., 0] = x[..., 0] - x[..., 2] / 2\n",
    "    y[..., 1] = x[..., 1] - x[..., 3] / 2\n",
    "    y[..., 2] = x[..., 0] + x[..., 2] / 2\n",
    "    y[..., 3] = x[..., 1] + x[..., 3] / 2\n",
    "    return y\n",
    "\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "\n",
    "def draw_detections(image, boxes, scores, class_ids, mask_alpha=0.3, mask_maps=None):\n",
    "    img_height, img_width = image.shape[:2]\n",
    "    size = min([img_height, img_width]) * 0.0006\n",
    "    text_thickness = int(min([img_height, img_width]) * 0.001)\n",
    "\n",
    "    mask_img = draw_masks(image, boxes, class_ids, mask_alpha, mask_maps)\n",
    "\n",
    "    # Draw bounding boxes and labels of detections\n",
    "    for box, score, class_id in zip(boxes, scores, class_ids):\n",
    "        color = colors[class_id]\n",
    "\n",
    "        x1, y1, x2, y2 = box.astype(int)\n",
    "\n",
    "        # Draw rectangle\n",
    "        cv2.rectangle(mask_img, (x1, y1), (x2, y2), color, 2)\n",
    "\n",
    "        label = class_names[class_id]\n",
    "        caption = f'{label} {int(score * 100)}%'\n",
    "        (tw, th), _ = cv2.getTextSize(text=caption, fontFace=cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                                      fontScale=size, thickness=text_thickness)\n",
    "        th = int(th * 1.2)\n",
    "\n",
    "        cv2.rectangle(mask_img, (x1, y1),\n",
    "                      (x1 + tw, y1 - th), color, -1)\n",
    "\n",
    "        cv2.putText(mask_img, caption, (x1, y1),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, size, (255, 255, 255), text_thickness, cv2.LINE_AA)\n",
    "\n",
    "    return mask_img\n",
    "\n",
    "\n",
    "def draw_masks(image, boxes, class_ids, mask_alpha=0.3, mask_maps=None):\n",
    "    mask_img = image.copy()\n",
    "\n",
    "    # Draw bounding boxes and labels of detections\n",
    "    for i, (box, class_id) in enumerate(zip(boxes, class_ids)):\n",
    "        color = colors[class_id]\n",
    "\n",
    "        x1, y1, x2, y2 = box.astype(int)\n",
    "\n",
    "        # Draw fill mask image\n",
    "        if mask_maps is None:\n",
    "            cv2.rectangle(mask_img, (x1, y1), (x2, y2), color, -1)\n",
    "        else:\n",
    "            crop_mask = mask_maps[i][y1:y2, x1:x2, np.newaxis]\n",
    "            crop_mask_img = mask_img[y1:y2, x1:x2]\n",
    "            crop_mask_img = crop_mask_img * (1 - crop_mask) + crop_mask * color\n",
    "            mask_img[y1:y2, x1:x2] = crop_mask_img\n",
    "\n",
    "    return cv2.addWeighted(mask_img, mask_alpha, image, 1 - mask_alpha, 0)\n",
    "\n",
    "\n",
    "def draw_comparison(img1, img2, name1, name2, fontsize=2.6, text_thickness=3):\n",
    "    (tw, th), _ = cv2.getTextSize(text=name1, fontFace=cv2.FONT_HERSHEY_DUPLEX,\n",
    "                                  fontScale=fontsize, thickness=text_thickness)\n",
    "    x1 = img1.shape[1] // 3\n",
    "    y1 = th\n",
    "    offset = th // 5\n",
    "    cv2.rectangle(img1, (x1 - offset * 2, y1 + offset),\n",
    "                  (x1 + tw + offset * 2, y1 - th - offset), (0, 115, 255), -1)\n",
    "    cv2.putText(img1, name1,\n",
    "                (x1, y1),\n",
    "                cv2.FONT_HERSHEY_DUPLEX, fontsize,\n",
    "                (255, 255, 255), text_thickness)\n",
    "\n",
    "    (tw, th), _ = cv2.getTextSize(text=name2, fontFace=cv2.FONT_HERSHEY_DUPLEX,\n",
    "                                  fontScale=fontsize, thickness=text_thickness)\n",
    "    x1 = img2.shape[1] // 3\n",
    "    y1 = th\n",
    "    offset = th // 5\n",
    "    cv2.rectangle(img2, (x1 - offset * 2, y1 + offset),\n",
    "                  (x1 + tw + offset * 2, y1 - th - offset), (94, 23, 235), -1)\n",
    "\n",
    "    cv2.putText(img2, name2,\n",
    "                (x1, y1),\n",
    "                cv2.FONT_HERSHEY_DUPLEX, fontsize,\n",
    "                (255, 255, 255), text_thickness)\n",
    "\n",
    "    combined_img = cv2.hconcat([img1, img2])\n",
    "    if combined_img.shape[1] > 3840:\n",
    "        combined_img = cv2.resize(combined_img, (3840, 2160))\n",
    "\n",
    "    return combined_img\n",
    "\n",
    "\n",
    "class YOLOSeg:\n",
    "\n",
    "    def __init__(self, path, conf_thres=0.7, iou_thres=0.5, num_masks=32):\n",
    "        self.conf_threshold = conf_thres\n",
    "        self.iou_threshold = iou_thres\n",
    "        self.num_masks = num_masks\n",
    "\n",
    "        # Initialize model\n",
    "        self.initialize_model(path)\n",
    "\n",
    "    def __call__(self, image):\n",
    "        return self.segment_objects(image)\n",
    "\n",
    "    def initialize_model(self, path):\n",
    "        self.session = onnxruntime.InferenceSession(path,\n",
    "                                                    providers=['CUDAExecutionProvider',\n",
    "                                                               'CPUExecutionProvider'])\n",
    "        # Get model info\n",
    "        self.get_input_details()\n",
    "        self.get_output_details()\n",
    "\n",
    "    def segment_objects(self, image):\n",
    "        input_tensor = self.prepare_input(image)\n",
    "\n",
    "        # Perform inference on the image\n",
    "        outputs = self.inference(input_tensor)\n",
    "\n",
    "        self.boxes, self.scores, self.class_ids, mask_pred = self.process_box_output(outputs[0])\n",
    "        self.mask_maps = self.process_mask_output(mask_pred, outputs[1])\n",
    "\n",
    "        return self.boxes, self.scores, self.class_ids, self.mask_maps\n",
    "\n",
    "    def prepare_input(self, image):\n",
    "        self.img_height, self.img_width = image.shape[:2]\n",
    "\n",
    "        input_img = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Resize input image\n",
    "        input_img = cv2.resize(input_img, (self.input_width, self.input_height))\n",
    "\n",
    "        # Scale input pixel values to 0 to 1\n",
    "        input_img = input_img / 255.0\n",
    "        input_img = input_img.transpose(2, 0, 1)\n",
    "        input_tensor = input_img[np.newaxis, :, :, :].astype(np.float32)\n",
    "\n",
    "        return input_tensor\n",
    "\n",
    "    def inference(self, input_tensor):\n",
    "        start = time.perf_counter()\n",
    "        outputs = self.session.run(self.output_names, {self.input_names[0]: input_tensor})\n",
    "\n",
    "        # print(f\"Inference time: {(time.perf_counter() - start)*1000:.2f} ms\")\n",
    "        return outputs\n",
    "\n",
    "    def process_box_output(self, box_output):\n",
    "\n",
    "        predictions = np.squeeze(box_output).T\n",
    "        num_classes = box_output.shape[1] - self.num_masks - 4\n",
    "\n",
    "        # Filter out object confidence scores below threshold\n",
    "        scores = np.max(predictions[:, 4:4+num_classes], axis=1)\n",
    "        predictions = predictions[scores > self.conf_threshold, :]\n",
    "        scores = scores[scores > self.conf_threshold]\n",
    "\n",
    "        if len(scores) == 0:\n",
    "            return [], [], [], np.array([])\n",
    "\n",
    "        box_predictions = predictions[..., :num_classes+4]\n",
    "        mask_predictions = predictions[..., num_classes+4:]\n",
    "\n",
    "        # Get the class with the highest confidence\n",
    "        class_ids = np.argmax(box_predictions[:, 4:], axis=1)\n",
    "\n",
    "        # Get bounding boxes for each object\n",
    "        boxes = self.extract_boxes(box_predictions)\n",
    "\n",
    "        # Apply non-maxima suppression to suppress weak, overlapping bounding boxes\n",
    "        indices = nms(boxes, scores, self.iou_threshold)\n",
    "\n",
    "        return boxes[indices], scores[indices], class_ids[indices], mask_predictions[indices]\n",
    "\n",
    "    def process_mask_output(self, mask_predictions, mask_output):\n",
    "\n",
    "        if mask_predictions.shape[0] == 0:\n",
    "            return []\n",
    "\n",
    "        mask_output = np.squeeze(mask_output)\n",
    "\n",
    "        # Calculate the mask maps for each box\n",
    "        num_mask, mask_height, mask_width = mask_output.shape  # CHW\n",
    "        masks = sigmoid(mask_predictions @ mask_output.reshape((num_mask, -1)))\n",
    "        masks = masks.reshape((-1, mask_height, mask_width))\n",
    "\n",
    "        # Downscale the boxes to match the mask size\n",
    "        scale_boxes = self.rescale_boxes(self.boxes,\n",
    "                                   (self.img_height, self.img_width),\n",
    "                                   (mask_height, mask_width))\n",
    "\n",
    "        # For every box/mask pair, get the mask map\n",
    "        mask_maps = np.zeros((len(scale_boxes), self.img_height, self.img_width))\n",
    "        blur_size = (int(self.img_width / mask_width), int(self.img_height / mask_height))\n",
    "        for i in range(len(scale_boxes)):\n",
    "\n",
    "            scale_x1 = int(math.floor(scale_boxes[i][0]))\n",
    "            scale_y1 = int(math.floor(scale_boxes[i][1]))\n",
    "            scale_x2 = int(math.ceil(scale_boxes[i][2]))\n",
    "            scale_y2 = int(math.ceil(scale_boxes[i][3]))\n",
    "\n",
    "            x1 = int(math.floor(self.boxes[i][0]))\n",
    "            y1 = int(math.floor(self.boxes[i][1]))\n",
    "            x2 = int(math.ceil(self.boxes[i][2]))\n",
    "            y2 = int(math.ceil(self.boxes[i][3]))\n",
    "\n",
    "            scale_crop_mask = masks[i][scale_y1:scale_y2, scale_x1:scale_x2]\n",
    "            crop_mask = cv2.resize(scale_crop_mask,\n",
    "                              (x2 - x1, y2 - y1),\n",
    "                              interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "            crop_mask = cv2.blur(crop_mask, blur_size)\n",
    "\n",
    "            crop_mask = (crop_mask > 0.5).astype(np.uint8)\n",
    "            mask_maps[i, y1:y2, x1:x2] = crop_mask\n",
    "\n",
    "        return mask_maps\n",
    "\n",
    "    def extract_boxes(self, box_predictions):\n",
    "        # Extract boxes from predictions\n",
    "        boxes = box_predictions[:, :4]\n",
    "\n",
    "        # Scale boxes to original image dimensions\n",
    "        boxes = self.rescale_boxes(boxes,\n",
    "                                   (self.input_height, self.input_width),\n",
    "                                   (self.img_height, self.img_width))\n",
    "\n",
    "        # Convert boxes to xyxy format\n",
    "        boxes = xywh2xyxy(boxes)\n",
    "\n",
    "        # Check the boxes are within the image\n",
    "        boxes[:, 0] = np.clip(boxes[:, 0], 0, self.img_width)\n",
    "        boxes[:, 1] = np.clip(boxes[:, 1], 0, self.img_height)\n",
    "        boxes[:, 2] = np.clip(boxes[:, 2], 0, self.img_width)\n",
    "        boxes[:, 3] = np.clip(boxes[:, 3], 0, self.img_height)\n",
    "\n",
    "        return boxes\n",
    "\n",
    "    def draw_detections(self, image, draw_scores=True, mask_alpha=0.4):\n",
    "        return draw_detections(image, self.boxes, self.scores,\n",
    "                               self.class_ids, mask_alpha)\n",
    "\n",
    "    def draw_masks(self, image, draw_scores=True, mask_alpha=0.5):\n",
    "        return draw_detections(image, self.boxes, self.scores,\n",
    "                               self.class_ids, mask_alpha, mask_maps=self.mask_maps)\n",
    "\n",
    "    def get_input_details(self):\n",
    "        model_inputs = self.session.get_inputs()\n",
    "        self.input_names = [model_inputs[i].name for i in range(len(model_inputs))]\n",
    "\n",
    "        self.input_shape = model_inputs[0].shape\n",
    "        self.input_height = self.input_shape[2]\n",
    "        self.input_width = self.input_shape[3]\n",
    "\n",
    "    def get_output_details(self):\n",
    "        model_outputs = self.session.get_outputs()\n",
    "        self.output_names = [model_outputs[i].name for i in range(len(model_outputs))]\n",
    "\n",
    "    @staticmethod\n",
    "    def rescale_boxes(boxes, input_shape, image_shape):\n",
    "        # Rescale boxes to original image dimensions\n",
    "        input_shape = np.array([input_shape[1], input_shape[0], input_shape[1], input_shape[0]])\n",
    "        boxes = np.divide(boxes, input_shape, dtype=np.float32)\n",
    "        boxes *= np.array([image_shape[1], image_shape[0], image_shape[1], image_shape[0]])\n",
    "\n",
    "        return boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on FastSAM in module fastsam.model object:\n",
      "\n",
      "class FastSAM(ultralytics.yolo.engine.model.YOLO)\n",
      " |  FastSAM(model: Union[str, pathlib.Path] = 'yolov8n.pt', task=None) -> None\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      FastSAM\n",
      " |      ultralytics.yolo.engine.model.YOLO\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __call__(self, source=None, stream=False, **kwargs)\n",
      " |      Calls the 'predict' function with given arguments to perform object detection.\n",
      " |  \n",
      " |  __getattr__(self, attr)\n",
      " |      Raises error if object has no requested attribute.\n",
      " |  \n",
      " |  export(self, **kwargs)\n",
      " |      Export model.\n",
      " |      \n",
      " |      Args:\n",
      " |          **kwargs : Any other args accepted by the predictors. To see all args check 'configuration' section in docs\n",
      " |  \n",
      " |  info(self, detailed=False, verbose=True)\n",
      " |      Logs model info.\n",
      " |      \n",
      " |      Args:\n",
      " |          detailed (bool): Show detailed information about model.\n",
      " |          verbose (bool): Controls verbosity.\n",
      " |  \n",
      " |  predict(self, source=None, stream=False, **kwargs)\n",
      " |      Perform prediction using the YOLO model.\n",
      " |      \n",
      " |      Args:\n",
      " |          source (str | int | PIL | np.ndarray): The source of the image to make predictions on.\n",
      " |                        Accepts all source types accepted by the YOLO model.\n",
      " |          stream (bool): Whether to stream the predictions or not. Defaults to False.\n",
      " |          **kwargs : Additional keyword arguments passed to the predictor.\n",
      " |                     Check the 'configuration' section in the documentation for all available options.\n",
      " |      \n",
      " |      Returns:\n",
      " |          (List[ultralytics.yolo.engine.results.Results]): The prediction results.\n",
      " |  \n",
      " |  train(self, **kwargs)\n",
      " |      Function trains models but raises an error as FastSAM models do not support training.\n",
      " |  \n",
      " |  val(self, **kwargs)\n",
      " |      Run validation given dataset.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from ultralytics.yolo.engine.model.YOLO:\n",
      " |  \n",
      " |  __init__(self, model: Union[str, pathlib.Path] = 'yolov8n.pt', task=None) -> None\n",
      " |      Initializes the YOLO model.\n",
      " |      \n",
      " |      Args:\n",
      " |          model (Union[str, Path], optional): Path or name of the model to load or create. Defaults to 'yolov8n.pt'.\n",
      " |          task (Any, optional): Task type for the YOLO model. Defaults to None.\n",
      " |  \n",
      " |  add_callback(self, event: str, func)\n",
      " |      Add a callback.\n",
      " |  \n",
      " |  benchmark(self, **kwargs)\n",
      " |      Benchmark a model on all export formats.\n",
      " |      \n",
      " |      Args:\n",
      " |          **kwargs : Any other args accepted by the validators. To see all args check 'configuration' section in docs\n",
      " |  \n",
      " |  clear_callback(self, event: str)\n",
      " |      Clear all event callbacks.\n",
      " |  \n",
      " |  fuse(self)\n",
      " |      Fuse PyTorch Conv2d and BatchNorm2d layers.\n",
      " |  \n",
      " |  load(self, weights='yolov8n.pt')\n",
      " |      Transfers parameters with matching names and shapes from 'weights' to model.\n",
      " |  \n",
      " |  reset_weights(self)\n",
      " |      Resets the model modules parameters to randomly initialized values, losing all training information.\n",
      " |  \n",
      " |  to(self, device)\n",
      " |      Sends the model to the given device.\n",
      " |      \n",
      " |      Args:\n",
      " |          device (str): device\n",
      " |  \n",
      " |  track(self, source=None, stream=False, persist=False, **kwargs)\n",
      " |      Perform object tracking on the input source using the registered trackers.\n",
      " |      \n",
      " |      Args:\n",
      " |          source (str, optional): The input source for object tracking. Can be a file path or a video stream.\n",
      " |          stream (bool, optional): Whether the input source is a video stream. Defaults to False.\n",
      " |          persist (bool, optional): Whether to persist the trackers if they already exist. Defaults to False.\n",
      " |          **kwargs (optional): Additional keyword arguments for the tracking process.\n",
      " |      \n",
      " |      Returns:\n",
      " |          (List[ultralytics.yolo.engine.results.Results]): The tracking results.\n",
      " |  \n",
      " |  tune(self, data: str, space: dict = None, grace_period: int = 10, gpu_per_trial: int = None, max_samples: int = 10, train_args: dict = None)\n",
      " |      Runs hyperparameter tuning using Ray Tune.\n",
      " |      \n",
      " |      Args:\n",
      " |          data (str): The dataset to run the tuner on.\n",
      " |          space (dict, optional): The hyperparameter search space. Defaults to None.\n",
      " |          grace_period (int, optional): The grace period in epochs of the ASHA scheduler. Defaults to 10.\n",
      " |          gpu_per_trial (int, optional): The number of GPUs to allocate per trial. Defaults to None.\n",
      " |          max_samples (int, optional): The maximum number of trials to run. Defaults to 10.\n",
      " |          train_args (dict, optional): Additional arguments to pass to the `train()` method. Defaults to {}.\n",
      " |      \n",
      " |      Returns:\n",
      " |          (dict): A dictionary containing the results of the hyperparameter search.\n",
      " |      \n",
      " |      Raises:\n",
      " |          ModuleNotFoundError: If Ray Tune is not installed.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Static methods inherited from ultralytics.yolo.engine.model.YOLO:\n",
      " |  \n",
      " |  is_hub_model(model)\n",
      " |      Check if the provided model is a HUB model.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from ultralytics.yolo.engine.model.YOLO:\n",
      " |  \n",
      " |  device\n",
      " |      Returns device if PyTorch model.\n",
      " |  \n",
      " |  names\n",
      " |      Returns class names of the loaded model.\n",
      " |  \n",
      " |  transforms\n",
      " |      Returns transform of the loaded model.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from ultralytics.yolo.engine.model.YOLO:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'FastSAM' object has no attribute 'img_height'. See valid attributes below.\nNone",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimg_height\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/AI/sam_research/FastSAM/fastsam/model.py:106\u001b[0m, in \u001b[0;36mFastSAM.__getattr__\u001b[0;34m(self, attr)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Raises error if object has no requested attribute.\"\"\"\u001b[39;00m\n\u001b[1;32m    105\u001b[0m name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\n\u001b[0;32m--> 106\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. See valid attributes below.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__doc__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'FastSAM' object has no attribute 'img_height'. See valid attributes below.\nNone"
     ]
    }
   ],
   "source": [
    "def process_mask_output(self, mask_predictions, mask_output):\n",
    "\n",
    "    if mask_predictions.shape[0] == 0:\n",
    "        return []\n",
    "\n",
    "    mask_output = np.squeeze(mask_output)\n",
    "\n",
    "    # Calculate the mask maps for each box\n",
    "    num_mask, mask_height, mask_width = mask_output.shape  # CHW\n",
    "    masks = sigmoid(mask_predictions @ mask_output.reshape((num_mask, -1)))\n",
    "    masks = masks.reshape((-1, mask_height, mask_width))\n",
    "\n",
    "    # Downscale the boxes to match the mask size\n",
    "    scale_boxes = self.rescale_boxes(self.boxes,\n",
    "                                (self.img_height, self.img_width),\n",
    "                                (mask_height, mask_width))\n",
    "\n",
    "    # For every box/mask pair, get the mask map\n",
    "    mask_maps = np.zeros((len(scale_boxes), self.img_height, self.img_width))\n",
    "    blur_size = (int(self.img_width / mask_width), int(self.img_height / mask_height))\n",
    "    for i in range(len(scale_boxes)):\n",
    "\n",
    "        scale_x1 = int(math.floor(scale_boxes[i][0]))\n",
    "        scale_y1 = int(math.floor(scale_boxes[i][1]))\n",
    "        scale_x2 = int(math.ceil(scale_boxes[i][2]))\n",
    "        scale_y2 = int(math.ceil(scale_boxes[i][3]))\n",
    "\n",
    "        x1 = int(math.floor(self.boxes[i][0]))\n",
    "        y1 = int(math.floor(self.boxes[i][1]))\n",
    "        x2 = int(math.ceil(self.boxes[i][2]))\n",
    "        y2 = int(math.ceil(self.boxes[i][3]))\n",
    "\n",
    "        scale_crop_mask = masks[i][scale_y1:scale_y2, scale_x1:scale_x2]\n",
    "        crop_mask = cv2.resize(scale_crop_mask,\n",
    "                            (x2 - x1, y2 - y1),\n",
    "                            interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "        crop_mask = cv2.blur(crop_mask, blur_size)\n",
    "\n",
    "        crop_mask = (crop_mask > 0.5).astype(np.uint8)\n",
    "        mask_maps[i, y1:y2, x1:x2] = crop_mask\n",
    "\n",
    "    return mask_maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'callbacks': defaultdict(<class 'list'>, {'on_pretrain_routine_start': [<function on_pretrain_routine_start at 0x3139239d0>], 'on_pretrain_routine_end': [<function on_pretrain_routine_end at 0x313923af0>], 'on_train_start': [<function on_train_start at 0x313923b80>], 'on_train_epoch_start': [<function on_train_epoch_start at 0x313923c10>], 'on_train_batch_start': [<function on_train_batch_start at 0x313923ca0>], 'optimizer_step': [<function optimizer_step at 0x313923d30>], 'on_before_zero_grad': [<function on_before_zero_grad at 0x313923dc0>], 'on_train_batch_end': [<function on_train_batch_end at 0x313923e50>], 'on_train_epoch_end': [<function on_train_epoch_end at 0x313923ee0>], 'on_fit_epoch_end': [<function on_fit_epoch_end at 0x313923f70>], 'on_model_save': [<function on_model_save at 0x31392e040>], 'on_train_end': [<function on_train_end at 0x31392e0d0>], 'on_params_update': [<function on_params_update at 0x31392e160>], 'teardown': [<function teardown at 0x31392e1f0>], 'on_val_start': [<function on_val_start at 0x31392e280>], 'on_val_batch_start': [<function on_val_batch_start at 0x31392e310>], 'on_val_batch_end': [<function on_val_batch_end at 0x31392e3a0>], 'on_val_end': [<function on_val_end at 0x31392e430>], 'on_predict_start': [<function on_predict_start at 0x31392e4c0>], 'on_predict_batch_start': [<function on_predict_batch_start at 0x31392e550>], 'on_predict_postprocess_end': [<function on_predict_postprocess_end at 0x31392e670>], 'on_predict_batch_end': [<function on_predict_batch_end at 0x31392e5e0>], 'on_predict_end': [<function on_predict_end at 0x31392e700>], 'on_export_start': [<function on_export_start at 0x31392e790>], 'on_export_end': [<function on_export_end at 0x31392e820>]}), 'predictor': <fastsam.predict.FastSAMPredictor object at 0x165d9d700>, 'model': SegmentationModel(\n",
      "  (model): Sequential(\n",
      "    (0): Conv(\n",
      "      (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      (act): SiLU(inplace=True)\n",
      "    )\n",
      "    (1): Conv(\n",
      "      (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      (act): SiLU(inplace=True)\n",
      "    )\n",
      "    (2): C2f(\n",
      "      (cv1): Conv(\n",
      "        (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (cv2): Conv(\n",
      "        (conv): Conv2d(96, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (m): ModuleList(\n",
      "        (0): Bottleneck(\n",
      "          (cv1): Conv(\n",
      "            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (cv2): Conv(\n",
      "            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): Conv(\n",
      "      (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      (act): SiLU(inplace=True)\n",
      "    )\n",
      "    (4): C2f(\n",
      "      (cv1): Conv(\n",
      "        (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (cv2): Conv(\n",
      "        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (m): ModuleList(\n",
      "        (0-1): 2 x Bottleneck(\n",
      "          (cv1): Conv(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (cv2): Conv(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (5): Conv(\n",
      "      (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      (act): SiLU(inplace=True)\n",
      "    )\n",
      "    (6): C2f(\n",
      "      (cv1): Conv(\n",
      "        (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (cv2): Conv(\n",
      "        (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (m): ModuleList(\n",
      "        (0-1): 2 x Bottleneck(\n",
      "          (cv1): Conv(\n",
      "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (cv2): Conv(\n",
      "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (7): Conv(\n",
      "      (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      (act): SiLU(inplace=True)\n",
      "    )\n",
      "    (8): C2f(\n",
      "      (cv1): Conv(\n",
      "        (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (cv2): Conv(\n",
      "        (conv): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (m): ModuleList(\n",
      "        (0): Bottleneck(\n",
      "          (cv1): Conv(\n",
      "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (cv2): Conv(\n",
      "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (9): SPPF(\n",
      "      (cv1): Conv(\n",
      "        (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (cv2): Conv(\n",
      "        (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (m): MaxPool2d(kernel_size=5, stride=1, padding=2, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "    (10): Upsample(scale_factor=2.0, mode='nearest')\n",
      "    (11): Concat()\n",
      "    (12): C2f(\n",
      "      (cv1): Conv(\n",
      "        (conv): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (cv2): Conv(\n",
      "        (conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (m): ModuleList(\n",
      "        (0): Bottleneck(\n",
      "          (cv1): Conv(\n",
      "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (cv2): Conv(\n",
      "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (13): Upsample(scale_factor=2.0, mode='nearest')\n",
      "    (14): Concat()\n",
      "    (15): C2f(\n",
      "      (cv1): Conv(\n",
      "        (conv): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (cv2): Conv(\n",
      "        (conv): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (m): ModuleList(\n",
      "        (0): Bottleneck(\n",
      "          (cv1): Conv(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (cv2): Conv(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (16): Conv(\n",
      "      (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      (act): SiLU(inplace=True)\n",
      "    )\n",
      "    (17): Concat()\n",
      "    (18): C2f(\n",
      "      (cv1): Conv(\n",
      "        (conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (cv2): Conv(\n",
      "        (conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (m): ModuleList(\n",
      "        (0): Bottleneck(\n",
      "          (cv1): Conv(\n",
      "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (cv2): Conv(\n",
      "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (19): Conv(\n",
      "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      (act): SiLU(inplace=True)\n",
      "    )\n",
      "    (20): Concat()\n",
      "    (21): C2f(\n",
      "      (cv1): Conv(\n",
      "        (conv): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (cv2): Conv(\n",
      "        (conv): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (m): ModuleList(\n",
      "        (0): Bottleneck(\n",
      "          (cv1): Conv(\n",
      "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (cv2): Conv(\n",
      "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (22): Segment(\n",
      "      (cv2): ModuleList(\n",
      "        (0): Sequential(\n",
      "          (0): Conv(\n",
      "            (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (1): Sequential(\n",
      "          (0): Conv(\n",
      "            (conv): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (2): Sequential(\n",
      "          (0): Conv(\n",
      "            (conv): Conv2d(512, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "      )\n",
      "      (cv3): ModuleList(\n",
      "        (0): Sequential(\n",
      "          (0): Conv(\n",
      "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv(\n",
      "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (1): Sequential(\n",
      "          (0): Conv(\n",
      "            (conv): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv(\n",
      "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (2): Sequential(\n",
      "          (0): Conv(\n",
      "            (conv): Conv2d(512, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv(\n",
      "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "      )\n",
      "      (dfl): DFL(\n",
      "        (conv): Conv2d(16, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      )\n",
      "      (proto): Proto(\n",
      "        (cv1): Conv(\n",
      "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (upsample): ConvTranspose2d(128, 128, kernel_size=(2, 2), stride=(2, 2))\n",
      "        (cv2): Conv(\n",
      "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (cv3): Conv(\n",
      "          (conv): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (cv4): ModuleList(\n",
      "        (0): Sequential(\n",
      "          (0): Conv(\n",
      "            (conv): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv(\n",
      "            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (1): Sequential(\n",
      "          (0): Conv(\n",
      "            (conv): Conv2d(256, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv(\n",
      "            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (2): Sequential(\n",
      "          (0): Conv(\n",
      "            (conv): Conv2d(512, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv(\n",
      "            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "), 'trainer': None, 'task': 'segment', 'ckpt': {'epoch': -1, 'best_fitness': None, 'model': SegmentationModel(\n",
      "  (model): Sequential(\n",
      "    (0): Conv(\n",
      "      (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      (act): SiLU(inplace=True)\n",
      "    )\n",
      "    (1): Conv(\n",
      "      (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      (act): SiLU(inplace=True)\n",
      "    )\n",
      "    (2): C2f(\n",
      "      (cv1): Conv(\n",
      "        (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (cv2): Conv(\n",
      "        (conv): Conv2d(96, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (m): ModuleList(\n",
      "        (0): Bottleneck(\n",
      "          (cv1): Conv(\n",
      "            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (cv2): Conv(\n",
      "            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): Conv(\n",
      "      (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      (act): SiLU(inplace=True)\n",
      "    )\n",
      "    (4): C2f(\n",
      "      (cv1): Conv(\n",
      "        (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (cv2): Conv(\n",
      "        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (m): ModuleList(\n",
      "        (0-1): 2 x Bottleneck(\n",
      "          (cv1): Conv(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (cv2): Conv(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (5): Conv(\n",
      "      (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      (act): SiLU(inplace=True)\n",
      "    )\n",
      "    (6): C2f(\n",
      "      (cv1): Conv(\n",
      "        (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (cv2): Conv(\n",
      "        (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (m): ModuleList(\n",
      "        (0-1): 2 x Bottleneck(\n",
      "          (cv1): Conv(\n",
      "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (cv2): Conv(\n",
      "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (7): Conv(\n",
      "      (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      (act): SiLU(inplace=True)\n",
      "    )\n",
      "    (8): C2f(\n",
      "      (cv1): Conv(\n",
      "        (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (cv2): Conv(\n",
      "        (conv): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (m): ModuleList(\n",
      "        (0): Bottleneck(\n",
      "          (cv1): Conv(\n",
      "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (cv2): Conv(\n",
      "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (9): SPPF(\n",
      "      (cv1): Conv(\n",
      "        (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (cv2): Conv(\n",
      "        (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (m): MaxPool2d(kernel_size=5, stride=1, padding=2, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "    (10): Upsample(scale_factor=2.0, mode='nearest')\n",
      "    (11): Concat()\n",
      "    (12): C2f(\n",
      "      (cv1): Conv(\n",
      "        (conv): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (cv2): Conv(\n",
      "        (conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (m): ModuleList(\n",
      "        (0): Bottleneck(\n",
      "          (cv1): Conv(\n",
      "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (cv2): Conv(\n",
      "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (13): Upsample(scale_factor=2.0, mode='nearest')\n",
      "    (14): Concat()\n",
      "    (15): C2f(\n",
      "      (cv1): Conv(\n",
      "        (conv): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (cv2): Conv(\n",
      "        (conv): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (m): ModuleList(\n",
      "        (0): Bottleneck(\n",
      "          (cv1): Conv(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (cv2): Conv(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (16): Conv(\n",
      "      (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      (act): SiLU(inplace=True)\n",
      "    )\n",
      "    (17): Concat()\n",
      "    (18): C2f(\n",
      "      (cv1): Conv(\n",
      "        (conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (cv2): Conv(\n",
      "        (conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (m): ModuleList(\n",
      "        (0): Bottleneck(\n",
      "          (cv1): Conv(\n",
      "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (cv2): Conv(\n",
      "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (19): Conv(\n",
      "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      (act): SiLU(inplace=True)\n",
      "    )\n",
      "    (20): Concat()\n",
      "    (21): C2f(\n",
      "      (cv1): Conv(\n",
      "        (conv): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (cv2): Conv(\n",
      "        (conv): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (m): ModuleList(\n",
      "        (0): Bottleneck(\n",
      "          (cv1): Conv(\n",
      "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (cv2): Conv(\n",
      "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (22): Segment(\n",
      "      (cv2): ModuleList(\n",
      "        (0): Sequential(\n",
      "          (0): Conv(\n",
      "            (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (1): Sequential(\n",
      "          (0): Conv(\n",
      "            (conv): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (2): Sequential(\n",
      "          (0): Conv(\n",
      "            (conv): Conv2d(512, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "      )\n",
      "      (cv3): ModuleList(\n",
      "        (0): Sequential(\n",
      "          (0): Conv(\n",
      "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv(\n",
      "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (1): Sequential(\n",
      "          (0): Conv(\n",
      "            (conv): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv(\n",
      "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (2): Sequential(\n",
      "          (0): Conv(\n",
      "            (conv): Conv2d(512, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv(\n",
      "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "      )\n",
      "      (dfl): DFL(\n",
      "        (conv): Conv2d(16, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      )\n",
      "      (proto): Proto(\n",
      "        (cv1): Conv(\n",
      "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (upsample): ConvTranspose2d(128, 128, kernel_size=(2, 2), stride=(2, 2))\n",
      "        (cv2): Conv(\n",
      "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (cv3): Conv(\n",
      "          (conv): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (cv4): ModuleList(\n",
      "        (0): Sequential(\n",
      "          (0): Conv(\n",
      "            (conv): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv(\n",
      "            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (1): Sequential(\n",
      "          (0): Conv(\n",
      "            (conv): Conv2d(256, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv(\n",
      "            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (2): Sequential(\n",
      "          (0): Conv(\n",
      "            (conv): Conv2d(512, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv(\n",
      "            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "), 'ema': None, 'updates': None, 'optimizer': None, 'train_args': {'task': 'segment', 'mode': 'train', 'model': 'yolov8s-seg.yaml', 'data': 'ultralytics/datasets/sa.yaml', 'epochs': 100, 'patience': 50, 'batch': 32, 'imgsz': 640, 'save': True, 'save_period': 10, 'cache': False, 'device': '0,1,2,3,4,5,6,7', 'workers': 16, 'project': 'sa_test', 'name': None, 'exist_ok': False, 'pretrained': False, 'optimizer': 'SGD', 'verbose': True, 'seed': 0, 'deterministic': True, 'single_cls': False, 'rect': False, 'cos_lr': False, 'close_mosaic': 0, 'resume': False, 'amp': True, 'overlap_mask': False, 'mask_ratio': 4, 'dropout': 0.0, 'val': True, 'split': 'val', 'save_json': False, 'save_hybrid': False, 'conf': None, 'iou': 0.7, 'max_det': 300, 'half': False, 'dnn': False, 'plots': True, 'source': None, 'show': False, 'save_txt': False, 'save_conf': False, 'save_crop': False, 'show_labels': True, 'show_conf': True, 'vid_stride': 1, 'line_width': None, 'visualize': False, 'augment': False, 'agnostic_nms': False, 'classes': None, 'retina_masks': False, 'boxes': True, 'format': 'torchscript', 'keras': False, 'optimize': False, 'int8': False, 'dynamic': False, 'simplify': False, 'opset': None, 'workspace': 4, 'nms': False, 'lr0': 0.01, 'lrf': 0.01, 'momentum': 0.937, 'weight_decay': 0.0005, 'warmup_epochs': 3.0, 'warmup_momentum': 0.8, 'warmup_bias_lr': 0.1, 'box': 7.5, 'cls': 0.5, 'dfl': 1.5, 'pose': 12.0, 'kobj': 1.0, 'label_smoothing': 0.0, 'nbs': 64, 'hsv_h': 0.015, 'hsv_s': 0.7, 'hsv_v': 0.4, 'degrees': 0.0, 'translate': 0.1, 'scale': 0.5, 'shear': 0.0, 'perspective': 0.0, 'flipud': 0.0, 'fliplr': 0.5, 'mosaic': 1.0, 'mixup': 0.0, 'copy_paste': 0.0, 'cfg': None, 'v5loader': False, 'tracker': 'botsort.yaml'}, 'date': '2023-06-21T01:07:44.997079', 'version': '8.0.107'}, 'cfg': None, 'ckpt_path': 'weights/FastSAM-s.pt', 'overrides': {'task': 'segment', 'data': 'ultralytics/datasets/sa.yaml', 'imgsz': 640, 'single_cls': False, 'model': './weights/FastSAM-s.pt'}, 'metrics': None, 'session': None}\n"
     ]
    }
   ],
   "source": [
    "print(model.__dict__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FastSAM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
